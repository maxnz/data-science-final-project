---
title: "Final Project"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    df_print: paged
knit: (function(inputFile, encoding) { 
           rmarkdown::render(inputFile, 
                             encoding = encoding, 
                             output_file = file.path(dirname(inputFile), 
                                                     'index.html')) 
       })
editor_options: 
  chunk_output_type: inline
---

```{r, setup, include = FALSE}
library(tidyverse)
library(maps)

years <- 2002:2019

matches <- readRDS("matches.rds") %>%
  mutate(week = case_when(
    event_type == "district_championship_division" ~ "dcmpd",
    event_type == "district_championship" ~ "dcmp",
    event_type == "championship_division" ~ "cmpd",
    event_type == "championship_finals" ~ "cmpf",
    event_type == "festival_of_champions" ~ "foc",
    TRUE ~ as.character(week)
  )) %>%
  mutate(week = factor(week, c("0", "1", "2", "3", "4", "5", "6", "7",
                               "dcmpd", "dcmp", "cmpd", "cmpf", "foc")))

scores <- matches %>%
  pivot_longer(cols = c("red_score", "blue_score"), 
               names_to = "alliance",
               values_to = "score") %>%
  mutate(alliance = as.factor(alliance))
scores$alliance <- recode_factor(scores$alliance,
                                 "red_score" = "red",
                                 "blue_score" = "blue")

teams <- readRDS("teams.rds") %>%
  filter(rookie_year != 2020) %>%
  rowwise() %>%
  mutate(years_competed = length(years))

matches_by_team <- scores %>%
  pivot_longer(cols = c("red_alliance_1", "red_alliance_2",
                        "red_alliance_3", "red_alliance_4",
                        "blue_alliance_1", "blue_alliance_2",
                        "blue_alliance_3", "blue_alliance_4"),
               names_to = "position",
               values_to = "team") %>%
  filter(!is.na(team)) %>%
  separate(position, sep = "_alliance_", into = c("team_alliance", "position")) %>%
  filter(alliance == team_alliance) %>%
  select(!team_alliance) %>%
  mutate(team_num = as.integer(str_remove(team, "frc")))
```

## Background

The FIRST Robotics Competition (FRC) is a competition where teams build a robot for 6ish weeks, then compete in one or more events to try to secure a spot in the championship.

### Competition Structure

An event consists of two parts, qualification and playoffs.
During the qualification matches, you play matches with algorithmically assigned teams against another alliance.
An alliance is a group of three teams that are working together to win against the other alliance.
There is a blue alliance and a red alliance.
During the playoff matches, the alliances are picked by the top 8 teams.
During most events, you pick two other teams to be part of your alliance through the rest of the playoffs.
If one of your robots breaks, you can request a backup robot to be added to your alliance to replace the broken robot.
At the championship, you pick three other teams, which means your backup is built-in to your alliance, because you only ever compete with three robots.

A regional is a competition of ~50-60 teams.
The winning alliance gets to go to the championship.
If a team in the winning alliance already qualified for the championship, then a team from the second-place alliance gets to go.
A district is a geographical area where teams attend two ~30-40 team events instead, followed by a district championship.
The top teams in the district championship get to go to the championship.

Ever since 2005, there have been two alliances of 3 teams each.
In 1999-2000 and 2002-2004 there were 2 team alliances, 2001 was 4v0, and 1992-1998 did not have alliances.
We only have match data from 2002 to the present.

Each year, teams are challenged by a new competition.
Everything from making robots play basketball to attacking a castle have been themes for competitions.
One year, teams may be asked to collect and launch balls into a target (2002, 2004, 2006, 2008, 2009, 2010, 2012, 2014, 2016, 2017, 2019) and the next year be asked to pick up inflatable shapes and place them onto pegs (2007, 2011).
There have also been years with stacking bins (2003, 2015), a year with tetras (basically a hollow tetrahedron that can be stacked) (2005), a year of ultimate frisbee (2013), and a year with milk crates (2018).

### Team Locations

The FIRST Robotics Competition (FRC) started in 1992 in a high school gym in Manchester, NH.
In 1992, there were 28 teams at 1 competition.
In 2019, there were over 3800 active teams competing at over 160 events worldwide.

Teams are located all over the world, with 31 countries represented in 2019.

```{r, countries, message = FALSE}
teams %>%
  filter(2019 %in% years) %>%
  group_by(country) %>%
  summarize(count = n()) %>%
  arrange(desc(count)) %>%
  knitr::kable(col.names = c("Country", "Number of Teams"),
               align = "ll")
```

The vast majority of the teams are located in the US.
Every state has at least 1 team.

```{r, states, message = FALSE}
teams %>%
  filter(2019 %in% years & country == "USA") %>%
  mutate(state_prov = case_when(
    state_prov == "CT" ~ "Connecticut",
    state_prov == "MI" ~ "Michigan",
    state_prov == "TX" ~ "Texas",
    TRUE ~ state_prov
  )) %>%
  group_by(state_prov) %>%
  summarize(count = n()) %>%
  arrange(desc(count)) %>%
  knitr::kable(col.names = c("State/Province", "Number of Teams"),
               align = "ll")
```

This is the distribution of US teams (note that 28 Hawaiian teams, 1 Alaskan team and 1 Puerto Rican team are omitted)

```{r, state_map, message = FALSE}
zip.codes <- read.csv("zipcode.csv")
teams %>%
  filter(2019 %in% years & country == "USA") %>%
  mutate(postal_code = parse_number(postal_code)) %>%
  left_join(zip.codes, by = c("postal_code" = "ZIP")) %>%
  filter(!is.na(LAT) & !is.na(LNG)) %>%
  filter(LNG > -140 & LAT > 20) %>%
  group_by(postal_code) %>%
  summarize(count = n(), LAT = LAT, LNG = LNG) %>%
  ggplot(aes(LNG, LAT, alpha = count)) +
  geom_point() +
  borders("state") +
  coord_quickmap()
```

## Performance Within a Season

To evaluate performance within a season, we can compare each week of competition.
Because the season is multiple weeks long, events happening on the same weekend are classified as being part of that "week" of competition.

In some years, performance does seem to improve, but in others it does not.
For example, in 2017 the performance increased slightly as the weeks of the season progressed:

```{r, scores_2017, message = FALSE}
scores %>%
  filter(year == 2017 & week %in% 0:6) %>%
  ggplot() +
  geom_violin(aes(week, score)) +
  labs(title = "Score Distribution by Week - 2017")
```

But in the 2009 season, there isn't any obvious improvement:

```{r, scores_2009, message = FALSE}
scores %>%
  filter(year == 2009 & week %in% 0:5) %>%
  ggplot() +
  geom_violin(aes(week, score)) +
  labs(title = "Score Distribution by Week - 2009")
```

If we include the championship events, we consistently see an improvement over the weeks prior.
Using 2009 again, we see that District Championships (`dcmp`), Championship Divisions (`cmpd`) and Championship Finals (`cmpf`) have a very noticeable improvement in scores.

```{r, scores_2009_all, message = FALSE}
scores %>%
  filter(year == 2009) %>%
  ggplot() +
  geom_violin(aes(week, score)) +
  labs(title = "Score Distribution by Week - 2009")
```

In many years, the difference between the Championship Finals and other levels can be drastic.
Take the 2016 season as an example.
The weeks progressed with minor improvements, the District Championships and Championship Divisions have an improvement in scores, but the Championship Finals have scores much higher.

```{r, scores_2016, message = FALSE}
scores %>%
  filter(year == 2016) %>%
  ggplot() +
  geom_violin(aes(week, score)) +
  labs(title = "Score Distribution by Week - 2016")
```

Using a boxplot, we can see that the average score in a Championship Finals match is almost double that of the average score in the Championship Divisions.

```{r, score_dist_2016, message = FALSE}
scores %>%
  filter(year == 2016) %>%
  ggplot() +
  geom_boxplot(aes(week, score)) +
  labs(title = "Score Distribution by Week - 2016")
```

## Comparing Performance Between Multiple Seasons

Because the competition changes every year, comparing raw scores from one year to the next is not a good measure of performance.
For example, the 2010 competition had an average match score of 4.07, while the 2018 competition had an average match score of 291.90.

```{r, year_score_avgs, message = FALSE}
scores %>%
  group_by(year) %>%
  summarize(avg_score = mean(score)) %>%
  knitr::kable(col.names = c("Year", "Average Score"),
               align = "ll")
```

We found that a good way to compare across years is to compute a team's performance relative to the rest of the teams in the competition that year.
By calculating the average score achieved by each team, we can determine what percentile each team achieved in a given year.

```{r, team_percentiles, message = FALSE}
team_avg_by_year <- matches_by_team %>%
  group_by(team, team_num, year) %>%
  summarize(avg_score = mean(score))

team_percentile_by_year <- data.frame(
  team = character(),
  team_num = integer(),
  year = integer(),
  avg_score = double(),
  percentile = double()
)

for (yr in years) {
  x <- team_avg_by_year %>%
    filter(year == yr)
  x$percentile <- ecdf(x$avg_score)(x$avg_score) * 100
  
  team_percentile_by_year <- bind_rows(team_percentile_by_year, x) %>%
    arrange(team_num)
}

team_percentile_avg <- team_percentile_by_year %>%
  group_by(team, team_num) %>%
  summarize(avg_performance = mean(percentile)) %>%
  ungroup()
```

For example, the performance of Team 2855 (Max's former team) is shown below:

```{r, performance_2855}
team_percentile_by_year %>%
  filter(team_num == 2855) %>%
  ggplot(aes(as.factor(year), percentile, group = 1)) +
  geom_line() +
  ylim(0, 100) +
  labs(title = "Performance of Team 2855",
       x = "Year",
       y = "Percentile")
```

As shown here, Team 2855 has had a couple of good years, but overall has been an ok team at best.

We can compare this to Team 3691, based out of Northfield High School:

```{r, performance_3691}
team_percentile_by_year %>%
  filter(team_num == 3691) %>%
  ggplot(aes(as.factor(year), percentile, group = 1)) +
  geom_line() +
  ylim(0, 100) +
  labs(title = "Performance of Team 3691",
       x = "Year",
       y = "Percentile")
```

At first glance, it seems like Team 3691 has been a better-performing team than Team 2855.
We can average all of a team's percentiles to determine an average performance.

```{r, performance_2855_3691_comp}
team_percentile_avg %>%
  filter(team_num %in% c(2855, 3691)) %>%
  left_join(teams, by = c("team_num" = "team_number")) %>%
  arrange(team_num) %>%
  select(team_num, nickname, rookie_year, years_competed, avg_performance) %>%
  head(20) %>%
  knitr::kable(col.names = c("Team #", "Nickname", "Rookie Year", 
                             "Years Competed", "Average Performance"),
               align = "lllll")
```

This confirms that Team 3691 is a better-performing team than Team 2855.

## Top Performing Teams of All Time

We can use our average performance metric to determine the top teams of all time:

```{r, top_performance}
team_percentile_avg %>%
  left_join(teams, by = c("team_num" = "team_number")) %>%
  arrange(desc(avg_performance)) %>%
  select(team_num, nickname, rookie_year, years_competed, state_prov, avg_performance) %>%
  head(20) %>%
  knitr::kable(col.names = c("Team #", "Nickname", "Rookie Year", 
                             "Years Competed", "State/Province", "Average Performance"),
               align = "llllll")
```

A team that stands out here is Team 2056 (aptly named "OP Robotics"), who has been able to perform at an impressive level in all 14 years they've competed, performing in the 99.91th percentile on average.
(Notice that the graph only shows the 95th to 100th percentiles, and yet they're still at the top.)

```{r, perform}
team_percentile_by_year %>%
  filter(team_num == 2056) %>%
  ggplot(aes(as.factor(year), percentile, group = 1)) +
  geom_point() +
  geom_line() +
  ylim(95, 100) +
  labs(title = "Performance of Team 2056",
       x = "Year",
       y = "Percentile")
```

Other teams that stand out are teams 2970 and 2098, which only competed for one season but were one of the best teams in that season.

## Performance of Longest Competing Teams

We can use our average performance metric to compute the performance of some of the oldest teams.
We have two possible ways to determine a team's "age":

- The number of seasons they have competed in
- The number of matches they have competed in

### Number of Seasons Competed vs Average Performance

With the FIRST Robotics Competition starting back in 1992, there have been 29 seasons (including 2020).
Only three teams exist that have competed in all of those seasons, though 9 teams from 1992 are still active in 2020 (they took a year or more off at some point).

```{r}
teams %>%
  filter(rookie_year == 1992 & 2020 %in% years) %>%
  arrange(team_number) %>%
  select(team_number, nickname, state_prov, rookie_year, years_competed) %>%
  knitr::kable(col.names = c("Team #", "Nickname", "State/Province",
                             "Rookie Year", "Seasons Competed"),
               align = "lllll")
```

These teams have been around a long time, but that isn't the norm.
That is a sample of only 9 out of about 8000 teams that have competed over the 29 seasons.
The average number of seasons competed in is around 6 years, with a median of 4.

```{r}
teams %>%
  ggplot() +
  geom_violin(aes(years_competed, 0)) +
  labs(title = "Lifespan of Teams",
       x = "Seasons Competed",
       y = "")
```

Using the number of seasons competed, we can take the top 31 teams based (31 because that is the cutoff between 24 and 25 seasons competed).

```{r}
team_percentile_avg %>%
  left_join(teams, by = c("team_num" = "team_number")) %>%
  arrange(desc(years_competed), team_num) %>%
  select(team_num, nickname, state_prov, rookie_year, years_competed, avg_performance) %>%
  head(31) %>%
  mutate(nickname = ifelse(team_num == 173, "RAGE Robotics", nickname)) %>%
  knitr::kable(col.names = c("Team #", "Nickname", "State/Province", 
                             "Rookie Year", "Seasons Competed", 
                             "Average Performance"),
               align = "llllll")

team_percentile_avg %>%
  left_join(teams, by = c("team_num" = "team_number")) %>%
  filter(years_competed >= 25) %>%
  ggplot() +
  geom_point(aes(as.factor(years_competed), avg_performance)) +
  labs(title = "Performance of Longest Competing Teams by Season",
       x = "Seasons Competed",
       y = "Average Performance")
```

As we can see from this graph, more seasons competed doesn't always equate to higher performance.
But, if we zoom out a bit and include all teams, we see that there is a distinct improvement over time.

```{r, years_vs_percentile, message = FALSE, warning = FALSE}
team_percentile_avg %>%
  left_join(teams, by = c("team_num" = "team_number")) %>%
  ggplot(aes(years_competed, avg_performance)) +
  geom_jitter(height = 0) +
  geom_smooth() +
  ylim(0, 100) +
  labs(title = "Seasons Competed vs Average Performance",
       x = "Seasons Competed",
       y = "Average Performance")
```

We can average all of the points for each number of seasons competed.
The improvement isn't uniform and doesn't always improve, especially above 15 seasons competed when the sample size is very small.

```{r, message = FALSE}
team_percentile_avg %>%
  left_join(teams, by = c("team_num" = "team_number")) %>%
  filter(!is.na(years_competed)) %>%
  group_by(years_competed) %>%
  summarize(avg_avg_performance = mean(avg_performance), num_teams = n()) %>%
  ggplot() +
  geom_point(aes(as.factor(years_competed), avg_avg_performance, size = num_teams)) +
  geom_line(aes(as.factor(years_competed), avg_avg_performance, group = 1)) +
  ylim(0, 100) +
  labs(title = "Years Competed vs Average of Average Performance",
       x = "Years Competed",
       y = "Average of Average Performance",
       size = "Number of Teams")
```

### Number of Matches Played vs Average Performance

This chart shows how many matches each team has played across the years 2002 to 2019.
As expected, teams with lower numbers have played more matches (because they've been around longer).

One team to notice is team 9999.
This team does not actually exist.
The number 9999 is used as a placeholder for a team that has not received a number yet.
This usually only happens during preseason and offseason events, though it seems to have happened in a week 0 regional event in 2004.

```{r, matches_played, message = FALSE}
matches_played_by_team <- matches_by_team %>%
  group_by(team_num) %>%
  summarize(played = n()) %>%
  ungroup()

matches_played_by_team %>%
  ggplot(aes(team_num, played)) +
  geom_point() +
  geom_smooth() +
  labs(title = "Matches Played by Team Number",
       x = "Team Number",
       y = "Matches Played")
```

We can look at the number of seasons competed vs number of matches played.
Because teams can attend multiple events, plus some teams attend the championship, the number of matches played can vary greatly.

```{r, seasons_vs_matches_played, message = FALSE, warning = FALSE}
matches_played_by_team %>%
  left_join(teams, by = c("team_num" = "team_number")) %>%
  ggplot(aes(years_competed, played)) +
  geom_jitter(height = 0, width = 0.3) +
  geom_smooth() +
  labs(title = "Seasons Competed vs Matches Played",
       x = "Seasons Competed",
       y = "Matches Played")
```

We can then compare the number of matches played by a team with their average performance.

```{r, matches_played_vs_percentile, message = FALSE, warning = FALSE}
team_percentile_avg %>%
  left_join(matches_played_by_team, by = "team_num") %>%
  ggplot(aes(played, avg_performance)) +
  geom_point() +
  geom_smooth() +
  ylim(0, 100) +
  labs(title = "Matches Played vs Average Performance",
       x = "Matches Played",
       y = "Average Performance")
```

This time we see a very distinct improvement with more experience.
This could be because of a few factors:

- More seasons mean better performance as well as more matches played
- Teams that attend the championship are usually there because they performed well in the regular season, meaning better performing teams get to play more matches

## Number of Events Attended and Performance

Our question here is to figure out how attending multiple events can impact your team's performance and development.
First, we will divide teams based on how many events they attended in a given season and see how the score percentile compares between number of events teams attended.

```{r, team_events_per_year, message = FALSE, include = FALSE}
team_events_per_year <- matches_by_team %>%
  group_by(team, team_num, year, event_key, event_type) %>%
  summarize() %>%
  ungroup() %>%
  group_by(team, team_num, year) %>%
  summarize(events = n(),
            non_cmp_events = length(event_key[event_type %in% c("regional", 
                                                                "district")]),
            attended_dcmp = "district_championship" %in% event_type | 
              "district_championship_division" %in% event_type,
            attended_cmp = "championship_division" %in% event_type,
            in_district = "district" %in% event_type)
```

```{r, message = FALSE, echo = FALSE}
team_events_per_year %>%
  left_join(team_percentile_by_year, by = c("team", "team_num", "year")) %>%
  filter(year == 2019) %>%
  ggplot() +
  geom_boxplot(aes(x = as.factor(events), y = percentile)) +
  labs(x = "Number of Events Attended",
       y = "Score Percentile for Year",
       title = as.character(yr))
```

These results aren't too shocking, but they give us some useful information to keep in mind later.
Clearly, the average score percentile for a team that attends a lot of events will be higher than a team that attends few since higher scoring teams are able to compete in more events.

It is interesting to see how high a team's score percentile needs to be in order for them to expect to compete in many events.
For example, in 2019 there were only a few teams that were below the 80th percentile that competed in 5 events.

```{r, message = FALSE, echo = FALSE}
team_events_per_year %>%
  filter(year == 2019) %>%
  inner_join(matches_by_team, by = c("team", "team_num", "year")) %>%
  group_by(team, year, events, week) %>%
  summarize(matches = n()) %>%
  ggplot() +
  geom_boxplot(aes(x = week, y = events)) +
  labs(x = "Week",
       y = "Number of Events the Teams Attended Throughout the Year",
       title = as.character(yr))
```

These boxplots don't reveal too many interesting trends, but they give us an understanding of how the average number of events a team participates is based on how far they make it in a season.
When we investigate the 2019 scores of the championship division and the championship finals, we can use the median number of events attended 4 and 5, respectively to compare the team scores between teams that attended a lot of events and few events.

```{r, message = FALSE, echo = FALSE}
team_avg_by_week_2019 <- team_events_per_year %>%
  filter(year == 2019) %>%
  inner_join(matches_by_team, by = c("team", "team_num", "year")) %>%
  group_by(team, year, events, week) %>%
  summarize(avg.score = mean(score))

week_avg_score_2019 <- team_avg_by_week_2019 %>%
  group_by(year, week) %>%
  summarise(avg.score = mean(avg.score))
```

```{r, message = FALSE}
team_avg_by_week_2019 %>%
  filter(week == "cmpd") %>%
  ggplot() +
  geom_boxplot(aes(x = (events >= 4), y = avg.score)) +
  labs(x = "Team Attended 4 or More Events in 2019",
       y = "Average Score at Championship Division")
```

This is the breakdown of teams in the championship division based on the 4 events attended cutoff we found previously.
This plot is showing that the teams that attended 4 or more events in 2019 score better in this event than those who didn't.
We can't use this as evidence that a team that has more experience will score better though since a winning team in a championship division will attend the championship finals, which adds to their event count.
A more interesting plot is this same boxplot for the championship finals below.

```{r, message = FALSE}
team_avg_by_week_2019 %>%
  filter(week == "cmpf") %>%
  ggplot() +
  geom_boxplot(aes(x = (events >= 5), y = avg.score)) +
  labs(x = "Team Attended 5 or More Events in 2019",
       y = "Average Score at Championship Finals")
```

This plot tells the opposite story from before.
The teams that made it to the finals who competed in more events actually performed worse in this case.
This shows experience in a single season isn't the most reliable indicator of season performance.

```{r, message = FALSE}
team_avg_by_week_2019 %>%
  filter(events >= 6) %>%
  ggplot() +
  geom_line(aes(x = week, y = avg.score, group = team, color = team)) +
  geom_line(data = week_avg_score_2019, mapping = aes(x = week, y = avg.score, group = year), size = 2) +
  labs(x = "Week of 2019 Season",
       y = "Team Average Score")
```

Here is a breakdown of score progression throughout the 2019 season for teams that competed in 6 or more events.
These are the teams that competed in the most events of all the teams.
All of the teams have positive trends that indicate the teams are still progressing through each of the many events they attend in the 2019 season.

The black line is the team average score each week for all the teams, not just the one's who attended a lot of events.
The scores of the more experienced teams are usually higher than this average for each week.
The black line has a few sudden jumps, which can be explained by the jump from regular season to postseason, and the jump to the finals.
The jumps are caused by the competition level increases that eliminate lower scoring teams.
